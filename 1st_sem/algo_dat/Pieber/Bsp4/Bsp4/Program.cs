using System;
using System.Collections;
using System.Linq;
using System.Text;
using System.Threading.Tasks;

namespace Bsp4
{
    class Program
    {
        static void Main(string[] args)
        {
            string blindText = "Hashtabelle\n(Weitergeleitet von Hashtable)\n\nIn der Informatik bezeichnet man eine spezielle Indexstruktur als Hashtabelle (englisch hash table oder hash map) bzw. Streuwerttabelle. Als Indexstruktur werden Hashtabellen verwendet, um Datenelemente in einer großen Datenmenge aufzufinden. Zu Hashtabellen alternative Index-Datenstrukturen sind beispielsweise Baumstrukturen (wie etwa ein B+-Baum) und die Skip-List. Hashtabellen zeichnen sich durch einen üblicherweise konstanten Zeitaufwand bei Einfüge- bzw. Entfernen-Operationen aus. Beim Einsatz einer Hashtabelle zur Suche in Datenmengen spricht man auch von einem Hashverfahren oder Streuspeicherverfahren.\nHashverfahren\n\nDas Hashverfahren ist ein Algorithmus zum Suchen von Datenobjekten in großen Datenmengen. Es basiert auf der Idee, dass eine mathematische Funktion die Position eines Objektes in einer Tabelle berechnet. Dadurch erübrigt sich das Durchsuchen vieler Datenobjekte, bis das Zielobjekt gefunden wurde.\nDer Algorithmus\n\nBeim Hashverfahren werden die Zieldaten in einer Hashtabelle gespeichert. Eine Hashfunktion berechnet zu jedem Datenobjekt einen Hashwert, der als Index in der Tabelle verwendet wird. Zum Berechnen dieses Hashwertes wird ein Schlüssel benötigt, der dieses Objekt eindeutig identifiziert. Dieser Schlüssel wird von der Hashfunktion zum Berechnen des Hashwertes verwendet. Das Datenobjekt wird an einer durch den Hashwert festgelegten Stelle (englisch Bucket) in der Tabelle gespeichert. Im Idealfall bekommt jedes Objekt einen eigenen Bucket. Hashfunktionen müssen jedoch nicht eindeutig sein, so dass zwei verschiedene Objekte denselben Hashwert haben können. Diesen Fall nennt man Kollision, er benötigt eine spezielle Behandlung durch das Verfahren.\n\nBei einer Suche in der Hashtabelle wird nun ähnlich vorgegangen. Zunächst wird aus einem Suchschlüssel wieder ein Hashwert berechnet, der den Bucket des gesuchten Datenobjektes bestimmt. Falls es zu einer Kollision gekommen ist, muss jetzt nur noch durch direkten Vergleich des Suchschlüssels mit den Objekten das gesuchte Ziel bestimmt werden.\n\nIn der Praxis wird die Tabelle als ein Array implementiert. Zur Behandlung von Kollisionen werden kollidierte Daten nach einer Ausweichstrategie in anderen alternativen Feldern oder in einer Liste gespeichert. Schlimmstenfalls können Kollisionen zu einer Entartung der Hashtabelle führen, wenn wenige Hashwerte sehr vielen Objekten zugewiesen wurden, während andere Hashwerte unbenutzt bleiben.\nKollisionen\n\nDa Hash-Funktionen im Allgemeinen nicht injektiv sind, können zwei unterschiedliche Schlüssel zum selben Hash-Wert, also zum selben Feld in der Tabelle führen. Dieses Ereignis wird als Kollision bezeichnet. In diesem Fall muss die Hashtabelle mehrere Werte an derselben Stelle aufnehmen. Um dieses Problem zu handhaben, gibt es diverse Kollisionsauflösungsstrategien.\n\nEine Möglichkeit wird offenes Hashing genannt. Wenn dabei ein Eintrag an eine schon belegte Stelle in der Tabelle abgelegt werden soll, wird stattdessen eine andere freie Stelle genommen. Es wird häufig zwischen drei Varianten unterschieden:\n\n    lineares Sondieren – es wird um ein konstantes Intervall verschoben nach einer freien Stelle gesucht. Meistens wird die Intervallgröße auf 1 festgelegt.\n    quadratisches Sondieren – Nach jedem erfolglosen Suchschritt wird das Intervall quadriert.\n    doppeltes Hashen – eine weitere Hash-Funktion liefert das Intervall.\n\nEine weitere Möglichkeit ist Kollisionsauflösung durch Verkettung. Anstelle der gesuchten Daten enthält die Hashtabelle hier Behälter (englisch Buckets), die alle Daten mit gleichem Hash-Wert aufnehmen. Bei einer Suche wird also zunächst der richtige Zielbehälter berechnet. Damit wird die Menge der möglichen Ziele erheblich eingeschränkt. Dennoch müssen abschließend die verbliebenen Elemente im Behälter durchsucht werden. Im schlimmsten Fall kann es passieren, dass alle Elemente gleiche Hash-Werte haben und damit im selben Bucket abgelegt werden. In der Praxis kann das aber durch die Wahl einer geeigneten Größe für die Hashtabelle sowie einer geeigneten Hash-Funktion vermieden werden. Oft wird die Verkettung durch eine lineare Liste pro Behälter realisiert.\nVorteile\n\nJe nach Anwendungsfall hat die Verwendung einer Hashtabelle Vorteile sowohl in der Zugriffszeit (gegenüber anderen Baumindexstrukturen) als auch im benötigten Speicherplatz (gegenüber gewöhnlichen Arrays).\n\nIdealerweise sollte die Hashfunktion für die zu speichernden Daten so gewählt sein, dass die Anzahl der Kollisionen minimiert wird und unter einer Konstante bleibt. Trifft dies zu, dann benötigt eine Hashtabelle mit n gespeicherten Elementen per Zugriff auf einen Hashtabellen-Eintrag im Mittel nur konstanten Zeitaufwand (O(1)). Je nach Hashfunktion muss die Hashtabelle zusätzliche ungenutzte Felder enthalten (in der Praxis üblicherweise 20 bis 30 Prozent), damit die Anzahl der Kollisionen beschränkt werden kann.\n\nIm Vergleich dazu ist der Zugriff auf ein Element in einem B-Baum in der Größenordnung von O(\\log n). Die komplette Baum-Datenstruktur benötigt Speicher in der Größenordnung von O(n).\nNachteile\n\nAls Füllgrad wird die Anzahl der gespeicherten Elemente geteilt durch die Anzahl aller Buckets bezeichnet. Mit steigendem Füllgrad wächst die Wahrscheinlichkeit einer Kollision und die Entartung nimmt zu. Dann kann nur eine Vergrößerung der Tabelle mit nachfolgender Restrukturierung wieder zu akzeptablem Laufzeitverhalten führen.\nKomplexität\n\nWurden Hash-Funktion und Größe der Hashtabelle geeignet gewählt, ist der Aufwand für die Suche in der Tabelle (englisch Look-Up) O(1). Wegen der möglichen Kollisionen hat eine Hashtabelle allerdings im so genannten Worst-Case ein sehr viel schlechteres Verhalten. Dieser wird mit O(n) abgeschätzt, wobei das n der Anzahl der in der Hashtabelle gespeicherten Einträge entspricht. Es werden dabei also alle Einträge in der Tabelle durchsucht.\nVarianten des Hashverfahrens\n\nEs gibt mehrere Varianten des Hashverfahrens, die sich für bestimmte Daten besser eignen. Ein wichtiger Faktor hierbei ist die Dynamik, mit der sich die Anzahl der Elemente ändert. Das offene Hashing löst dieses Problem, nimmt aber Einbußen bei den Zugriffszeiten in Kauf. Das geschlossene Hashing ist hingegen auf explizite Strategien zur Kollisionsbehandlung angewiesen. Vorsicht: Die Bezeichnungen „offenes“ bzw. „geschlossenes Hashing“ werden auch in genau umgekehrter Bedeutung verwendet.\nHashing mit Verkettung\n\nBeim Hashing mit Verkettung (englisch separate chaining) ist die Hash-Tabelle so strukturiert, dass jeder Behälter eine dynamische Datenstruktur aufnehmen kann – beispielsweise eine Liste oder einen Baum. Jeder Schlüssel wird dann in dieser Datenstruktur eingetragen oder gesucht. So ist es problemlos möglich, mehrere Schlüssel in einem Behälter abzulegen, was allerdings zu mehr oder weniger verlängerten Zugriffszeiten führt. Die Effizienz des Zugriffs wird dabei davon bestimmt, wie schnell Datensätze in die gewählte Datenstruktur eingefügt und darin wiedergefunden werden können. Hashing mit Verkettung ist bei Datenbanken eine sehr gängige Indizierungsvariante, wobei sehr große Datenmengen mittels Hashtabellen indiziert werden. Die Größe der Buckets ist in Datenbanksystemen ein Vielfaches der Sektorengröße des Speichermediums. Der Grund dafür ist, dass die Datenmenge nicht mehr im Hauptspeicher gehalten werden kann. Bei einer Suchanfrage muss das Datenbanksystem die Buckets sektorenweise einlesen.\nHashing mit offener Adressierung\n\nDieses Verfahren wird abgekürzt auch offenes Hashing, bezogen auf die offene Adressierung, aber auch geschlossenes Hashing, bezogen auf die begrenzte Anzahl möglicher Schlüssel im Behälter, genannt.\n\nBeim Hashing mit offener Adressierung kann jedem Behälter nur eine feste Anzahl von Schlüsseln zugewiesen werden. Häufig wählt man einfach einen einzigen möglichen Schlüssel pro Behälter. Im Kollisionsfall muss dann nach einem alternativen Behälter gesucht werden. Dabei geht man so vor, dass man für m Behälter eine ganze Folge von m Hash-Funktionen definiert. Führt die Anwendung der ersten Hash-Funktion, nennen wir sie h0, zu einer Kollision, so wendet man h1 an. Führt diese ebenfalls zu einer Kollision (d. h. der entsprechende Behälter ist bereits belegt), so wendet man h2 an, und so weiter bis hm-1. Die Bezeichnung „offene Adressierung“ ergibt sich aus der Eigenschaft, dass durch Kollisionen gleiche Schlüssel unterschiedliche Adressen zugewiesen bekommen können.\nCuckoo Hashing\n\nCuckoo Hashing ist ein weiteres Verfahren, Kollisionen in einer Tabelle zu vermeiden. Der Name leitet sich vom Verhalten des Kuckucks ab, Eier aus einem Nest zu entfernen, um ein eigenes Ei hineinzulegen.\n\nDas Prinzip ist, zwei Hash-Funktionen einzusetzen. Das ergibt zwei mögliche Speicherorte in einer Hashtabelle, was immer eine konstante Zugriffszeit garantiert. Ein neuer Schlüssel wird an einem der zwei möglichen Orte gespeichert. Sollte die erste Zielposition besetzt sein, wird der bereits vorhandene Schlüssel auf seine alternative Position versetzt und an seiner Stelle der neue Schlüssel gespeichert. Sollte die alternative Position besetzt sein, so wird wiederum der Schlüssel auf dieser Position auf seine alternative Position transferiert, und so fort. Wenn diese Prozedur zu einer unendlichen Schleife führt (üblicherweise bricht man nach \\log n Schritten ab), wird die Hashtabelle mit zwei neuen Hash-Funktionen neu aufgebaut. Die Wahrscheinlichkeit für ein solches Rehashing liegt in der Größenordnung von O(1/n) für jedes Einfügen.\nAlgorithmen\nLineares Sondieren\n\nDie einfachste Möglichkeit zur Definition einer solchen Folge besteht darin, so lange den jeweils nächsten Behälter zu prüfen, bis man auf einen freien Behälter trifft. Die Definition der Folge von Hash-Funktionen sieht dann so aus:\n\nh_i(x) = (h(x) + i) \\; \bmod~m\n\nDie Anwendung des Modulo hat mit der begrenzten Zahl von Behältern zu tun: Wurde der letzte Behälter geprüft, so beginnt man wieder beim ersten Behälter. Das Problem dieser Methode ist, dass sich so schnell Ketten oder Cluster bilden und die Zugriffszeiten im Bereich solcher Ketten schnell ansteigen. Das lineare Sondieren ist daher wenig effizient. Sein Vorteil ist jedoch, dass – im Gegensatz zu anderen Sondierungsverfahren – alle Behälter der Tabelle benutzt werden.\nQuadratisches Sondieren\n\nWie beim linearen Sondieren wird nach einem neuen freien Speicher gesucht, allerdings nicht sequenziell, sondern mit stetig quadratisch wachsendem Abstand zur ursprünglichen Position und in beide Richtungen. Verursacht h(k) eine Kollision, so werden nacheinander h(k) + 1 , h(k) - 1 , h(k) + 4 , h(k) - 4 , h(k) + 9 usw. probiert. In Formeln ausgedrückt: h_i(x) = \\left(h(x) + (-1)^{i+1} \\cdot \\left\\lceil\frac{i}{2}\right\rceil^2\right) \bmod~m\n\nDen ständigen Wechsel des Vorzeichens bei dieser Kollisionsstrategie nennt man auch „alternierendes quadratisches Sondieren“ oder „quadratisches Sondieren mit Verfeinerung“. Wählt man die Anzahl der Behälter geschickt (nämlich m = 4 \\cdot j + 3, m ist Primzahl), so erzeugt jede Sondierungsfolge h_0(x) bis h_{m-1}(x) eine Permutation der Zahlen 0 bis m-1; so wird also sichergestellt, dass jeder Behälter getroffen wird.\n\nQuadratisches Sondieren ergibt keine Verbesserung für die Wahrscheinlichkeit eine Sondierung durchführen zu müssen (h_0(x) = h_0(y)), kann aber die Wahrscheinlichkeit von Kollisionen während der Sondierung (h_0(x) = h_k(y)) herabsetzen, d. h. Clusterbildung wird vermieden.\nDoppel-Hashing\n\nBeim Doppel-Hashing werden zwei unabhängige Hash-Funktionen h und h' angewandt. Diese heißen unabhängig, wenn die Wahrscheinlichkeit für eine sogenannte Doppelkollision, d. h. h(x)=h(y) \and h'(x)=h'(y) gleich 1/m^2 und damit minimal ist. Die Folge von Hash-Funktionen, die nun mittels h und h' gebildet werden, sieht so aus:\nh_i(x) = (h(x)+h'(x)\\cdot i) ~ \\bmod ~ m\n\nDie Kosten für diese Methode sind nahe den Kosten für ein ideales Hashing.\nBrent-Hashing\n\nBeim Brent-Hashing wird geprüft, ob der Platz an dem das Element eingefügt werden soll, frei ist. Ist das der Fall, dann wird das Element dort eingefügt. Ist der Platz jedoch belegt, dann wird anhand des gerade berechneten Platzes jeweils für das einzufügende Element und für das Element, das schon an dem Platz ist, ein neuer Platz in der Tabelle berechnet. Sind die beiden neu berechneten Plätze auch belegt, wiederholt sich die Prozedur für den neu berechneten belegten Platz des einzufügenden Elementes. Wird jedoch für das einzufügende Element ein Platz berechnet der frei ist, wird das Element dort eingefügt. Ist der Platz jedoch belegt und der berechnete Platz frei für das Element, das im vorherigen Durchlauf den Platz für das einzufügende Element belegt hat, dann werden die beiden Plätze der Elemente vertauscht und damit konnte das einzufügende Element in der Tabelle untergebracht werden.\nDynamisches Hashing\n\nBei steigendem Füllgrad der Tabelle steigt die Wahrscheinlichkeit von Kollisionen deutlich an. Spätestens wenn die Anzahl der indizierten Datensätze größer ist, als die Kapazität der Tabelle, werden Kollisionen unvermeidbar. Das bedeutet, dass das Verfahren einen zunehmenden Aufwand zur Kollisionslösung aufwenden muss. Um dies zu vermeiden, wird beim Dynamischen Hashing die Hashtabelle bei Bedarf vergrößert. Dies hat jedoch zwangsläufig Auswirkungen auf den Wertebereich der Hash-Funktion, der nun ebenfalls erweitert werden muss. Eine Änderung der Hash-Funktion wiederum hat jedoch den nachteiligen Effekt, dass sich ebenfalls die Hash-Werte für bereits gespeicherte Daten ändern. Für das dynamische Hashing wurde dafür eigens eine Klasse von Hash-Funktionen entwickelt, deren Wertebereich vergrößert werden kann, ohne die bereits gespeicherten Hash-Werte zu verändern.\nVorteile\n\n    Es gibt keine obere Grenze für das Datenvolumen\n    Einträge können ohne Probleme gelöscht werden\n    Adresskollisionen führen nicht zur Clusterbildung.\n\nNachteile\n\nFalls nicht eine ordnungserhaltende Hashfunktion zum Einsatz kam:\n    kein effizientes Durchlaufen der Einträge nach einer Ordnung\n    keine effiziente Suche nach dem Eintrag mit dem kleinsten oder größten Schlüssel\n\nAnwendung\n\nEin Anwendungsfall ist das Assoziative Array (auch Map, Lookup Table, Dictionary oder Wörterbuch). Das Nachschlagen der mit einem Schlüssel assoziierten Daten kann mittels einer Hashtabelle schnell und elegant implementiert werden.\n\nWichtig sind Hashtabellen auch für Datenbanken zur Indizierung von Tabellen. Ein sogenannter Hashindex kann unter günstigen Bedingungen zu idealen Zugriffszeiten führen.\n\nDes Weiteren finden Hashtabellen Einsatz in praktisch jeder modernen Applikation. Hier werden sie zur Implementierung von Mengen (Sets) oder eines Caches verwendet. Symboltabellen, die bei Compilern oder Interpretern Verwendung finden, werden meistens auch als Hashtabelle realisiert.\nEinsatz in Datenbanken\n\nHashtabellen ermöglichen so eine sehr schnelle Suche in großen Datenmengen, da mit der Berechnung des Hashwertes in einem einzigen Schritt die Anzahl der möglichen Zielobjekte eingeschränkt wird. Damit gehören Hashtabellen zu den effizientesten Indexstrukturen. Ein großer Nachteil ist jedoch die Gefahr der Entartung durch Kollisionen, die bei einem stetigen Wachstum der Datenmenge unausweichlich sind (wenn die Tabelle nicht vergrößert und jedes darin enthaltene Element neu gehasht wird). Siehe dazu Kollision. Daher, wegen ungünstiger IO-Zugriffsmuster, wenn die Hashtabelle auf einem Datenträger gespeichert ist und der fehlenden Möglichkeit Intervalle gemäß einer Ordnungsrelation effizient zu iterieren, muss der Einsatz von Datenbanksystemen gegenüber alternativen Indexdatenstruktien, wie z. B. B+-Bäumen, abgewogen werden.\n\nDie meisten Hashfunktionen erlauben nicht die Bewegung zum nächsten oder vorherigen Datensatz gemäß einer Ordnungsrelation, da sie gezielt die Daten „mischen“, um sie gleichmäßig im Werteraum zu verteilen. Nur spezielle „ordnungserhaltende“ Hashfunktionen erlauben eine derartige Iteration gemäß ihrer Ordnungsrelation und damit die Abfrage mit Ungleichheitsverknüpfungen („größer als“, „kleiner als“) oder den sortierten Zugriff auf alle Werte.[1] Um solche Verfahren effizient einsetzen zu können, ist meist eine vorherige Analyse der Datenverteilung notwendig. Sie finden daher meist nur in Datenbanksystemen Anwendung, die eine solche Analyse auch beispielsweise zur Anfrageoptimierung durchführen.\n\n\nVerteilte Hashtabelle\n\nEine verteilte Hashtabelle (engl. distributed hash table, DHT) ist eine Datenstruktur, die zum Beispiel dazu genutzt werden kann, den Speicherort einer Datei in einem P2P-System zu speichern. Dabei steht die Dezentralisierung und die Effizienz der Datenspeicherung im Vordergrund.\n\nDie Daten werden möglichst gleichmäßig über die vorhandenen Speicherknoten verteilt. Jeder Speicherknoten entspricht dabei einem Eintrag in der Hashtabelle. Die selbstorganisierende Datenstruktur kann den Ausfall, Beitritt und Austritt von Knoten abbilden. Die Grundlage für verteilte Hashtabellen bilden konsistente Hash-Funktionen.\n\nMan unterscheidet DHTs nach dem Speicherschema. Die Daten können direkt innerhalb der DHT abgelegt werden (direct storage) oder in der DHT kann ein Verweis auf die Daten vorgehalten werden (indirect storage). Direct Storage bietet sich nur für kleine Daten (< 1 kB) an, da sonst das System zu unflexibel würde.\nEigenschaften\n\nEigenschaften von DHTs sind:\n\n    Fehlertoleranz: Das System sollte zuverlässig funktionieren, auch wenn Knoten ausfallen oder das System verlassen.\n    Lastenverteilung: Schlüssel werden gleichmäßig auf alle Knoten verteilt.\n    Robustheit: Das System sollte ,,korrekt\" funktionieren können, auch wenn ein Teil (möglicherweise ein Großteil) der Knoten versucht, das System zu stören.\n    Selbstorganisation: Es ist keine manuelle Konfiguration nötig.\n    Skalierbarkeit: Das System sollte in der Lage sein, auch mit einer großen Anzahl von Knoten funktionsfähig zu bleiben.\n\nPrinzipielle Arbeitsweise\n\nMittels einer Hash-Funktion werden den Datenobjekten Schlüssel in einem linearen Wertebereich vergeben, welcher möglichst gleichmäßig über die Knoten der Knotenmenge verteilt wird. Jeder Knoten ist dabei mindestens für einen Teilbereich des Schlüsselraumes zuständig, oft sind jedoch auch mehrere Knoten für denselben Bereich verantwortlich, wobei sich die Zuständigkeiten dynamisch ändern. Ein Beitrittsprotokoll regelt die Aufnahme neuer Knoten in das existierende System. Das Protokoll stellt dann die Verbindungen zu den Nachbarknoten her und regelt üblicherweise auch die Konstruktion von Routingtabellen.\n\nDie Routingtabellen werden von den DHT-Knoten zur Ermittlung anderer Knoten benutzt, die für bestimmte Datensätze zuständig sind. Die Definition der ,,Entfernung\" ist dabei mit der Struktur und der Topologie verbunden und variiert in unterschiedlichen Systemen. Sie muss nicht zwingend mit der physikalischen Organisation der Knoten übereinstimmen. Eine verteilte Hashtabelle, die ihre Knoten in einem euklidischen Raum platziert, könnte den Knoten mit dem geringsten euklidischen Abstand zu einem Schlüssel wählen. Die Routingtabellen sollen es jedem Knoten erlauben, den nächsten Knoten zu einem Schlüssel in O(log n) Suchschritten zu erreichen.\n\nDurch eine generische Schnittstelle, die nur zwei Funktionen publish(Schlüssel, Inhalt) und lookup(Schlüssel) anbietet, lassen sich die implementierten Algorithmen auswechseln.\nImplementierungen\n\nDerzeit existieren unter anderem folgende Implementierungen verteilter Hashtabellen:\n\n    Chord\n    Kademlia - Strukturen basierend auf diesem Algorithmus existieren in mehreren P2P-Netzwerken, sind allerdings meist nicht untereinander kompatibel. Implementierungen:\n        KAD - Entwicklung des eMule-Entwicklungsteams, basierend auf dem Kademlia-Algorithmus, um die mit der Zeit ausfallenden Server des eDonkey2000-Netzwerks zu ersetzen.\n        Mojito - Entwicklung des LimeWire-Entwicklungsteams zur schnellen Quellenermittlung innerhalb des Gnutella-Netzwerks.\n    Pastry\n\nAnwendungen\nDHTs zur Datenspeicherung\n\n    OpenDHT\n    Bamboo\n    The Chord/DHash Project\n    FreePastry\n    TomP2P\n\nSoftware\n\n    apt-p2p (Paketverwaltungssystem): Verteiltes Update auf Basis von apt\n    Azureus (Filesharing-Client): BitTorrent-Client\n    BitComet: BitTorrent-Client\n    BitTorrent (ab Version 4.1.0)\n    Coral: Verteilungsnetzwerk für Inhalte\n    Deluge (BitTorrent-Client)\n    eDonkey2000, Name: Overnet\n    eMule (ab Version 0.40) und aMule (ab Version 2.1.0), Name: Kad\n    Free Download Manager: freier Download-Manager, der auch BitTorrent und DHT beherrscht\n    Freenet: Anonymer Datenspeicher.\n    Halite: BitTorrent-Client\n    KTorrent: BitTorrent-Client\n    LimeWire (Name: Mojito)\n    RetroShare: serverloser Instant Messenger, anonymes/Filesharing, Newsgroup, Voice over IP, E-Mail\n    MLDonkey (Overnet und Kademlia)\n    qBittorrent: BitTorrent-Client\n    rTorrent: BitTorrent-Client\n    Transmission (BitTorrent): BitTorrent-Client\n    CSpace: Instant Messenger mit Kademlia\n    µTorrent: BitTorrent-Client\n    YaCy: verteilte Suchmaschine\n\nDHT-Forschung\n\n    Project IRIS (Infrastructure for Resilient Internet Systems)";

            string[] array = blindText.Split(new char[] { ' ', '.', ',', ';', ':', '\n' }, StringSplitOptions.RemoveEmptyEntries);

            Hashtable<int, string> ht = new Hashtable<int, string>(array.Length / 10);

            Timing t = new Timing();

            Console.Write("Inserting {0} values to the Hashtable with {1} buckets... ", array.Length, ht.Count);

            t.StartTime();

            foreach (string item in array)
            {
                ht.Add(item.GetHashCode(), item);
            }

            t.StopTime();

            Console.WriteLine("done; took {0} ({1} ticks)", t.Result().ToString(), t.Result().Ticks);

            string test, result;

            Console.WriteLine("Checking speed of hash function");

            Random r = new Random();

            for (int i = 0; i < 20; i++)
            {
                test = array[r.Next(array.Length - 1)];
                Console.Write("Looking for {0}: ", test);

                t.StartTime();

                result = ht[test.GetHashCode()];

                t.StopTime();

                Console.WriteLine("{0}; took {1} ({2} ticks)", result, t.Result().ToString(), t.Result().Ticks);
            }

            Console.ReadLine();
        }
    }
}
